\section{Benchmark e processing dell'output}
\label{cap:benchmark-process}

Poiché le domande dell'homework richiedono di misurare non solo i tempi di esecuzione totali, ma anche le performance
di singoli metodi implementati, abbiamo effettuato le misurazioni direttamente con gli strumenti offerti dal linguaggio di programmazione scelto. Abbiamo usato \mintinline{c++}{std::chrono::steady_clock}, una classe della libreria standard C++ che rappresenta un orologio monotono (i tempi misurati sono strettamente crescenti), particolarmente adatta a misurare intervalli di tempo. Tutti i tempi sono misurati in microsecondi ($\mu{}s$). \\

\subsection{Misurazione}

Il tempo di esecuzione totale dei programmi implementati tiene conto anche del tempo necessario a leggere il grafo dal file di input e a salvarlo in una struttura dati intermedia idonea.

\subsection{Output}
\label{sub:output}

Al contrario dei precedenti homework, l'output dei programmi implementati è molto ricco. Le informazioni stampate a video sono infatti:

\begin{itemize}
    \item \codeinline{filename}: nome del file di input;
    \item \codeinline{k}: numero di iterazioni dell'algoritmo randomizzato stimate per ottenere il vero \textit{min-cut} con probabilità $\geq \frac{1}{n}$;
    \item \codeinline{full\_contraction}: tempi di esecuzione della procedura di contrazione del grafo fino a ridurlo a 2 soli vertici. Vi è una stampa per ogni iterazione \codeinline{k};
    \item \codeinline{min\_cut}: migliore soluzione del problema \textit{min-cut} individuata dall'algoritmo randomizzato;
    \item \codeinline{program\_time}: tempo di esecuzione dell'intero programma;
    \item \codeinline{discovery\_time}: numero di microsecondi necessari a trovare il miglior valore di \textit{min-cut} la prima volta.
\end{itemize}

\subsection{Processing dell'output}

Gli script \codeinline{run.sh} e \codeinline{runall.sh} e lo script Python \codeinline{process.py} sono usati per convertire l'output dei programmi in file CSV. Il loro funzionamento è il seguente:

\begin{itemize}
    \item \codeinline{runall.sh} lancia \codeinline{run.sh} su ogni algoritmo implementato, e redirige l'output in un file in formato CSV nella cartella \codeinline{benchmark};
    \item \codeinline{run.sh} legge ogni grafo di input dalla cartella \codeinline{dataset}. Esso esegue l'algoritmo desiderato passando l'output allo script \codeinline{process.py} tramite \codeinline{pipe} ($\vert$). Questo file si occupa inoltre di estrarre il numero di nodi dal nome del file e di confrontare l'output del programma con la soluzione attesa del grafo di input.
    \item \codeinline{process.py} legge l'output del programma descritto nella sezione \ref{sub:output} e redirige a \codeinline{stdout} la corrispondente linea del file CSV da generare.
\end{itemize}
 
\subsection{Analisi}
 
\noindent Lo script Python \codeinline{benchmark/analysis.py} è invece usato per analizzare i file CSV generati i grafici e le tabelle informative usate in questa relazione.

\noindent Lo script trasforma i dati grezzi in dati manipolabili e li
elabora estraendone le informazioni principali e mostrandole sotto
forma di grafici e tabelle. Di seguito sono riportate ad alto
livello le fasi eseguite dallo script:

\begin{enumerate}
    \item Lettura di tutti i file CSV e trasformazione in DataFrames \codeinline{Pandas};
    \item Esecuzione di controlli (asserzioni) sulla struttura dei dati
      letti e sul loro significato, per assicurare che CSV siano esenti da errori;
    \item Elaborazione dei dati. In particolare i benchmark vengono raggruppati
      per algoritmo in una singola tabella, e per ogni riga
      viene mantenuto il dato con il tempo di esecuzione minore. La
      colonna degli output invece mantiene il valore mediano tra tutti
      i benchmark per ogni algoritmo.
    \item Estrazione della conoscenza tramite la creazione di tabelle
      e grafici con semplici primitive integrate nello script.
    \label{script-phase-analysis}
\end{enumerate}

\subsection{Affidabilità dei dati}

\noindent Per rendere i risultati del benchmark quanto più stabili e
affidabili possibile, abbiamo preso le seguenti precauzioni:

\begin{itemize}
    \item Abbiamo usato sempre lo stesso computer per misurare il
      tempo di esecuzione dei programmi implementati;
    \item Abbiamo chiuso tutti i programmi in foreground e
      disabilitato quanti più servizi possibile in background;
    \item Abbiamo disabilitato la connessione Internet del computer
      scelto;
    \item Abbiamo fatto più misurazioni in tempi differenti. Di tutte
      le misurazioni effettuate è poi stata scelta la minima per
      elaborazioni e grafici.
\end{itemize}

\noindent Il computer usato per effettuare i benchmark degli algoritmi
ha le seguenti caratteristiche:

\begin{itemize}
    \item \textbf{Sistema Operativo}: Windows 10 Education 64 bit;
    \item \textbf{CPU}: Intel Core i5 6600K 3.50 GHz
    \item \textbf{RAM}: 16 GB;
\end{itemize}
